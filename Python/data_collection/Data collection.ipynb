{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Ben & Jerry's ice cream flavors & reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good to scrape\n",
    "- Ben & Jerry's (include pints, Netflix Originals, cores, etc.)\n",
    "   - Ben & Jerry's graveyard (no images or reviews)\n",
    "- Haagen Dazs\n",
    "- Breyers (no images)\n",
    "- Talenti (no images)\n",
    "- Dreyer's/Edy's (no images) -- seems to be an error in their website where reviews are mixed together for different flavors\n",
    "\n",
    "Maybe\n",
    "- Enlightened -- biased reviews\n",
    "- Rebel -- biased reviews\n",
    "- Wall's UK (Cornetto, Magnum,  Cart D'or) -- slow to load\n",
    "\n",
    "Other\n",
    "- Baskin Robbins, Graeter's, Halo Top, Blue Bell, Blue Bunny, Serendipity, So Delicious, Moevenpick, Alden's, Tillamook, Hood, Jeni's, Cold Stone, Gifford's, Brighams, Walpole Creamery, Friendly's, Nestle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0eeb04645a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mreq_main_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmain_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq_main_page\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mproducts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//a[@class=\"landing-item\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html, etree\n",
    "import time\n",
    "\n",
    "# home = \"https://www.benjerry.com/\"\n",
    "# url = home + \"flavors/ice-cream-pints\"\n",
    "# req_main_page = requests.get(url)\n",
    "# main_page = html.fromstring(req_main_page.content)\n",
    "# products = response.xpath('//a[@class=\"landing-item\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/files/live/sites/systemsite/files/flavors/products/us/pint/open-closed-pints/boots-on-the-moooon-landing.png\n",
      "Boots on the Moooo’n™ A Universe of Milk Chocolate Ice Cream with Fudge Cows & Toffee Meteor Clusters Orbiting a Sugar Cookie Dough Core While Space Force works to get boots (back) on the moon, this cosmic concoction will launch your dreams into orbit. With fudgy astronaut cows & toffee meteors, space couldn't be any sweeter. Unless the moon was made out of sugar cookie dough. Which for this limited-time flavor, it actually is!\n"
     ]
    }
   ],
   "source": [
    "for product in [products[0]]:    \n",
    "    product_img_url = home + product.xpath('//img[@class=\"image-alt-name\"]/@src')[0]\n",
    "    \n",
    "    req_product_page = requests.get(home + product.xpath(\"@data-producturl\")[0])\n",
    "    product_page = html.fromstring(req_product_page.content)\n",
    "    \n",
    "    product_name = product_page.xpath('//h1[@class=\"productDetails-name\"]/text()')[0]\n",
    "    product_subhead = product_page.xpath('//h2[@id=\"productDetails-product_desc\"]/text()')[0].strip()\n",
    "    product_story = product_page.xpath('//p[@id=\"productDetails-product_story\"]/text()')[0].strip()\n",
    "    \n",
    "#     product_rating = product_page.xpath('//span[@itemprop=\"ratingValue\"]/text()')\n",
    "#     product_rating_ct = product_page.xpath('//span[@itemprop=\"reviewCount\"]/text()')\n",
    "#     product_img_url = product_page.xpath('//img[@class=\"lazy desktop lazy-stack loaded\"]/@src')\n",
    "\n",
    "    print(product_name, product_subhead, product_story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver      \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ben & Jerry's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize driver\n",
    "driver = webdriver.Chrome('./chromedriver.exe')\n",
    "\n",
    "# --- get starting page with list of products ---\n",
    "# define starting page\n",
    "home = \"https://www.benjerry.com/\"\n",
    "url = home + \"flavors/ice-cream-pints\"\n",
    "\n",
    "# load the page\n",
    "driver.get(url)  \n",
    "time.sleep(3)\n",
    "\n",
    "# get the list of products\n",
    "products = driver.find_elements_by_xpath('.//a[@class=\"landing-item\"]')\n",
    "product = products[0]\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_product_page(product, driver, completed):\n",
    "    product_name = product.get_attribute(\"data-pname\")\n",
    "    if product_name in completed:\n",
    "        return True\n",
    "    else:\n",
    "        completed.append(product_name)\n",
    "        product_page_url = home + product.get_attribute(\"data-producturl\")\n",
    "        driver.get(product_page_url)\n",
    "        time.sleep(2) # wait for ratings to load\n",
    "        return False\n",
    "\n",
    "def get_product_page_content(driver):\n",
    "    product_name = driver.find_element_by_xpath('.//h1[@class=\"productDetails-name\"]').text.strip()\n",
    "    print(\"Starting product:\", product_name) \n",
    "    product_subhead = driver.find_element_by_xpath('.//h2[@id=\"productDetails-product_desc\"]').text.strip()\n",
    "    product_story = driver.find_element_by_xpath('.//p[@id=\"productDetails-product_story\"]').text.strip()\n",
    "    product_rating = driver.find_element_by_xpath('.//span[@itemprop=\"ratingValue\"]').text\n",
    "    product_rating_ct = driver.find_element_by_xpath('.//span[@itemprop=\"reviewCount\"]').text\n",
    "    \n",
    "    ingred_expand = driver.find_element_by_xpath('.//li[@class=\"bjnt_flavorListItem\"]/div[contains(@class,\"accordion-basic\")]')\n",
    "    ingred_expand.click()\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        ingred_info = driver.find_element_by_xpath('.//div[@class=\"package-ingredients\"]').text.strip()\n",
    "    except NoSuchElementException: \n",
    "        ingred_info = \"NA\"\n",
    "    \n",
    "#     print(product_name, product_subhead, product_story, product_rating, product_rating_ct)\n",
    "    \n",
    "    # filename for reviews data and image\n",
    "    product_filename = \"-\".join(product_name.encode(\"ascii\", \"ignore\").decode().replace('\"','').strip().split())\n",
    "    \n",
    "    # product info\n",
    "    df = pd.DataFrame({\"key\": [product_filename], \"name\": [product_name],\n",
    "                       \"subhead\": [product_subhead], \"description\": [product_story],\n",
    "                      \"rating\": [product_rating], \"rating_count\": [product_rating_ct],\n",
    "                      \"ingredients\":[ingred_info]})\n",
    "    \n",
    "    if os.path.isfile(\"products_bj.csv\"):\n",
    "        df.to_csv(\"products_bj.csv\", mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(\"products_bj.csv\", mode=\"w\", header=True, index=False)\n",
    "    \n",
    "    return product_filename\n",
    "    \n",
    "\n",
    "def get_reviews_single_page(driver, product_filename):\n",
    "    reviews_expand = driver.find_element_by_xpath('.//div[@id=\"expReviews\"]')\n",
    "    reviews_expand.click()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # avoid the 2 review summary (most helpful, most harmful) and avoid review responses \n",
    "    reviews_single_page = driver.find_elements_by_xpath('.//div[contains(@class,\"bv-content-item-avatar-offset\") and not(ancestor::div[@class=\"bv-section-summary\"] or ancestor::li[contains(@class,\"bv-secondary-content-clientresponse\")])]')\n",
    "    \n",
    "    review_author, review_date, review_stars, review_title, review_yes, review_no, review_text = [], [], [], [], [], [], []\n",
    "    for review in reviews_single_page:\n",
    "        try:\n",
    "            review_author.append(review.find_element_by_xpath('.//button[@itemprop=\"author\"]/span').text)\n",
    "        except NoSuchElementException: \n",
    "            review_author.append(\"NA\") # anonymous\n",
    "        review_date.append(review.find_element_by_xpath('.//meta[@itemprop=\"datePublished\"]').get_attribute(\"content\"))\n",
    "        review_stars.append(review.find_element_by_xpath('.//meta[@itemprop=\"ratingValue\"]').get_attribute(\"content\"))\n",
    "        try:\n",
    "            review_title.append(review.find_element_by_xpath('.//h3[@itemprop=\"headline\"]').text)\n",
    "        except NoSuchElementException: \n",
    "            review_title.append(\"NA\")\n",
    "        try:\n",
    "            review_yes.append(review.find_element_by_xpath('.//button[contains(@class,\"feedback-yes\")]//span[@class=\"bv-content-btn-count\"]').text)\n",
    "            review_no.append(review.find_element_by_xpath('.//button[contains(@class,\"feedback-no\")]//span[@class=\"bv-content-btn-count\"]').text)\n",
    "        except NoSuchElementException:\n",
    "            review_yes.append(\"0\")\n",
    "            review_no.append(\"0\")\n",
    "        review_text.append(review.find_element_by_xpath('.//div[@class=\"bv-content-summary-body-text\"]/p').text)\n",
    "            \n",
    "    product_filename_column = [product_filename]*len(reviews_single_page) \n",
    "    df = pd.DataFrame({\"key\": product_filename_column, \"author\": review_author, \"date\": review_date, \n",
    "                       \"stars\": review_stars, \"title\": review_title, \"helpful_yes\": review_yes, \"helpful_no\": review_no, \n",
    "                       \"text\": review_text})\n",
    "\n",
    "    if os.path.isfile(\"reviews_bj.csv\"):\n",
    "        df.to_csv(\"reviews_bj.csv\", mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(\"reviews_bj.csv\", mode=\"w\", header=True, index=False)\n",
    "        \n",
    "    print(\"Processed\", len(reviews_single_page), \"reviews\")\n",
    "        \n",
    "def pagination(driver):\n",
    "    try:\n",
    "        next_page = driver.find_element_by_xpath('.//a[descendant::span[@class=\"bv-content-btn-pages-next\"]]') \n",
    "    except NoSuchElementException: \n",
    "        more = False\n",
    "    else:\n",
    "        more = True\n",
    "        next_page.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    return more # True means there is another page to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo not found\n",
      "Starting product: Cold Brew Caramel Latte\n",
      "Processed 8 reviews\n",
      "Processed 2 reviews\n",
      "Starting product: Wake & \" No Bake \" Cookie Dough Core\n",
      "Processed 8 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Starting product: Brownie Batter Core\n",
      "Processed 8 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 10 reviews\n",
      "Starting product: Cookies & Cream Cheesecake Core\n",
      "Processed 8 reviews\n",
      "Processed 30 reviews\n",
      "Processed 19 reviews\n",
      "Starting product: Karamel Sutra® Core\n",
      "Processed 8 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 26 reviews\n",
      "Starting product: Peanut Butter Fudge Core\n",
      "Processed 8 reviews\n",
      "Processed 11 reviews\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-353e5c310c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misCompleted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mproduct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.//a[@class=\"landing-item\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# make directory for images and reviews\n",
    "if not os.path.isdir(\"images_bj\"):\n",
    "    os.mkdir(\"images_bj\")\n",
    "\n",
    "# get list of images (circumvent lazy load)\n",
    "product_img_urls = []\n",
    "for prod in products:\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView()\", prod)\n",
    "    try:\n",
    "        photo = prod.find_element_by_xpath('.//img[@class=\"image-alt-name\"]')\n",
    "    except NoSuchElementException:\n",
    "        print(\"Photo not found\") \n",
    "        product_img_urls.append(\"NA\")\n",
    "    else:\n",
    "        product_img_urls.append(photo.get_attribute(\"src\"))\n",
    "\n",
    "i = 0\n",
    "df1=pd.read_csv(\"products_bj.csv\")\n",
    "completed = df1[\"name\"].values.tolist()\n",
    "# completed = []\n",
    "while i < len(products):\n",
    "    isCompleted = go_to_product_page(product, driver, completed)\n",
    "    if isCompleted:\n",
    "        i += 1\n",
    "        product = driver.find_elements_by_xpath('.//a[@class=\"landing-item\"]')[i]\n",
    "        continue\n",
    "        \n",
    "    product_filename = get_product_page_content(driver)\n",
    "        \n",
    "    # get all reviews for product\n",
    "    nextPage = True\n",
    "    while nextPage == True:\n",
    "        get_reviews_single_page(driver, product_filename)\n",
    "        nextPage = pagination(driver)\n",
    "    \n",
    "    # get product image\n",
    "    product_img_url = product_img_urls[i]\n",
    "    if product_img_url != \"NA\":\n",
    "        urllib.request.urlretrieve(product_img_url, \"images_bj/%s.png\" % product_filename)      \n",
    "    time.sleep(2.5)\n",
    "        \n",
    "    # return to start\n",
    "    driver.get(url)\n",
    "    i += 1\n",
    "    product = driver.find_elements_by_xpath('.//a[@class=\"landing-item\"]')[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haagen-Dazs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize driver\n",
    "driver = webdriver.Chrome('./chromedriver.exe')\n",
    "\n",
    "# --- get starting page with list of products ---\n",
    "# define starting page\n",
    "home = \"https://www.haagendazs.us/\"\n",
    "url = home + \"products\"\n",
    "\n",
    "# load the page\n",
    "driver.get(url)  \n",
    "time.sleep(3)\n",
    "\n",
    "# get the list of products\n",
    "products = driver.find_elements_by_xpath('//div[contains(@class,\"flavors\")]')\n",
    "product = products[0]\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_product_page(product, driver, completed):\n",
    "    product_name = product.find_element_by_xpath('.//div[@class=\"name-product\"]//span').text.strip()\n",
    "    if product_name in completed:\n",
    "        return True\n",
    "    else:\n",
    "        completed.append(product_name)\n",
    "        product_page_url = product.find_element_by_xpath('.//a').get_attribute(\"href\")\n",
    "        driver.get(product_page_url)\n",
    "        time.sleep(2.5) # wait for ratings to load\n",
    "        return False\n",
    "\n",
    "def get_product_page_content(driver):\n",
    "    product_name = driver.find_element_by_xpath('.//div[@itemprop=\"name\"]/h1').text.strip()\n",
    "    print(\"Starting product:\", product_name) \n",
    "    product_description = driver.find_element_by_xpath('.//span[@itemprop=\"description\"]//p').text.strip()\n",
    "    product_rating = driver.find_element_by_xpath('.//div[@itemprop=\"ratingValue\"]').text\n",
    "    product_rating_ct = driver.find_element_by_xpath('.//meta[@itemprop=\"reviewCount\"]').get_attribute(\"content\")\n",
    "    \n",
    "    # ------ INGREDIENTS ---------\n",
    "    fail = False\n",
    "    # normal label\n",
    "    try:\n",
    "        ingred_expand = driver.find_element_by_xpath('.//a[@class=\"nutritional-table\"]')\n",
    "        ingred_expand.click()\n",
    "        time.sleep(0.5)\n",
    "    except NoSuchElementException:\n",
    "        fail = True\n",
    "    else:\n",
    "        try:\n",
    "            ingred_info = driver.find_element_by_xpath('.//div[@class=\"ingredients\"]/p').text.lstrip(\"Ingredients:  \").split(\" Contains:\")[0]\n",
    "        except NoSuchElementException: \n",
    "            ingred_info = \"NA\"\n",
    "        finally:\n",
    "            ingred_close = driver.find_element_by_xpath('.//a[@class=\"close\"]')\n",
    "            ingred_close.click()\n",
    "            time.sleep(0.5)\n",
    "    # smart-label\n",
    "    if fail == True:\n",
    "        try:\n",
    "            ingred_expand = driver.find_element_by_xpath('.//a[@class=\"info-smart-label-url\"]')\n",
    "        except NoSuchElementException: \n",
    "            ingred_info = \"NA\"\n",
    "        else:\n",
    "            ingred_expand.click()\n",
    "            time.sleep(2)\n",
    "            \n",
    "            try:\n",
    "                frame = driver.find_element_by_xpath('.//iframe[contains(@src,\"smartlabel\")]')\n",
    "            except NoSuchElementException: \n",
    "                ingred_info = \"NA\"\n",
    "            else:\n",
    "                time.sleep(0.5)\n",
    "#                 WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.XPATH,'.//iframe[contains(@src,\"smartlabel\")]'')))\n",
    "                driver.switch_to.frame(frame)\n",
    "\n",
    "                ingred_nav = driver.find_element_by_xpath('.//div[contains(@class,\"TabNavigation\")]//span[contains(text(),\"Ingredients\")]')\n",
    "                ingred_nav.click()\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                ingred_list = driver.find_elements_by_xpath('.//div[contains(@class,\"IngredientList\")]//a')\n",
    "                ingred_info = \", \".join([ingred.text for ingred in ingred_list])\n",
    "\n",
    "                driver.switch_to.default_content()\n",
    "                ingred_close = driver.find_element_by_xpath('.//a[@class=\"modal-vanilla-close\"]')\n",
    "                ingred_close.click()\n",
    "                time.sleep(0.5)\n",
    "    # -----------------------------\n",
    "    \n",
    "    # filename for reviews data and image\n",
    "    product_filename = \"-\".join(product_name.encode(\"ascii\", \"ignore\").decode().strip().split())\n",
    "    \n",
    "    # product info\n",
    "    df = pd.DataFrame({\"key\": [product_filename], \"name\": [product_name],\n",
    "                       \"description\": [product_description],\n",
    "                      \"rating\": [product_rating], \"rating_count\": [product_rating_ct],\n",
    "                      \"ingredients\": [ingred_info]})\n",
    "    \n",
    "    if os.path.isfile(\"products_hd.csv\"):\n",
    "        df.to_csv(\"products_hd.csv\", mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(\"products_hd.csv\", mode=\"w\", header=True, index=False)    \n",
    "    \n",
    "    # get product image\n",
    "    product_img_url = driver.find_element_by_xpath('.//div[@class=\"hero-details\"]//img').get_attribute(\"src\")\n",
    "    urllib.request.urlretrieve(product_img_url, \"images_hd/%s.png\" % product_filename)      \n",
    "    time.sleep(2)\n",
    "    \n",
    "    return product_filename\n",
    "    \n",
    "\n",
    "def get_reviews_single_page(driver, product_filename):\n",
    "    time.sleep(3) # wait for reviews to load\n",
    "    \n",
    "    reviews_single_page = driver.find_elements_by_xpath('.//li[contains(@class,\"bv-content-review\")]')\n",
    "    \n",
    "    review_author, review_date, review_stars, review_title, review_yes, review_no, review_text = [], [], [], [], [], [], []\n",
    "    tastes, ingredients, textures, likes = [], [], [], []\n",
    "    for review in reviews_single_page:\n",
    "        try:\n",
    "            review_author.append(review.find_element_by_xpath('.//div[@class=\"bv-author-avatar\"]//h3').text)\n",
    "        except NoSuchElementException: \n",
    "            review_author.append(\"NA\") # anonymous\n",
    "        review_date.append(review.find_element_by_xpath('.//meta[@itemprop=\"datePublished\"]').get_attribute(\"content\"))\n",
    "        review_stars.append(review.find_element_by_xpath('.//meta[@itemprop=\"ratingValue\"]').get_attribute(\"content\"))\n",
    "        try:\n",
    "            review_title.append(review.find_element_by_xpath('.//h3[@itemprop=\"headline\"]').text)\n",
    "        except NoSuchElementException: \n",
    "            review_title.append(\"NA\")\n",
    "        try:\n",
    "            review_yes.append(review.find_element_by_xpath('.//button[contains(@class,\"feedback-yes\")]//span[@class=\"bv-content-btn-count\"]').text)\n",
    "            review_no.append(review.find_element_by_xpath('.//button[contains(@class,\"feedback-no\")]//span[@class=\"bv-content-btn-count\"]').text)\n",
    "        except NoSuchElementException:\n",
    "            review_yes.append(\"0\")\n",
    "            review_no.append(\"0\")\n",
    "        review_text.append(review.find_element_by_xpath('.//div[@class=\"bv-content-summary-body-text\"]/p').text)\n",
    "        \n",
    "        # misc   \n",
    "        try:\n",
    "            secondary_labels = review.find_elements_by_xpath('.//li[@class=\"bv-content-secondary-ratings-label\"]')\n",
    "        except NoSuchElementException: \n",
    "            tastes.append(\"NA\")\n",
    "            ingredients.append(\"NA\")\n",
    "            textures.append(\"NA\")\n",
    "\n",
    "        else:\n",
    "            if len(secondary_labels) == 0:\n",
    "                tastes.append(\"NA\")\n",
    "                ingredients.append(\"NA\")\n",
    "                textures.append(\"NA\")\n",
    "            else:\n",
    "                for label in secondary_labels:\n",
    "                    label_text = label.text\n",
    "                    rating_bar = label.find_element_by_xpath('./following-sibling::li[1]')\n",
    "                    rating_span = rating_bar.find_element_by_xpath('.//span[contains(@class,\"bv-content-secondary-ratings-value\")]')\n",
    "                    rating0_100 = rating_span.get_attribute(\"class\").split(\"-\")[-1] # this is a number between 0 and 100\n",
    "                    rating1_5 = int(rating0_100)/20\n",
    "\n",
    "                    if label_text == \"Overall Taste\":\n",
    "                        tastes.append(rating1_5)\n",
    "                    elif label_text == \"Quality of Ingredients\":\n",
    "                        ingredients.append(rating1_5)\n",
    "                    elif label_text == \"Overall Texture\":\n",
    "                        textures.append(rating1_5)\n",
    "                    \n",
    "        try:\n",
    "            dimensions = review.find_elements_by_xpath('.//ul[@class=\"bv-content-data-tag-dimensions\"]//li[@class=\"bv-content-data-value\"]')\n",
    "        except NoSuchElementException: \n",
    "            likes.append(\"NA\")\n",
    "        else:\n",
    "            if len(dimensions) == 0:\n",
    "                likes.append(\"NA\")\n",
    "            else:\n",
    "                likes.append(\"\".join([d.text for d in dimensions]))\n",
    "            \n",
    "    product_filename_column = [product_filename]*len(reviews_single_page) \n",
    "    df = pd.DataFrame({\"key\": product_filename_column, \"author\": review_author, \"date\": review_date, \n",
    "                       \"stars\": review_stars, \"title\": review_title, \"helpful_yes\": review_yes, \"helpful_no\": review_no, \n",
    "                       \"text\": review_text, \"taste\": tastes, \"ingredients\":ingredients, \"texture\": textures, \"likes\": likes})\n",
    "\n",
    "    if os.path.isfile(\"reviews_hd.csv\"):\n",
    "        df.to_csv(\"reviews_hd.csv\", mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(\"reviews_hd.csv\", mode=\"w\", header=True, index=False)\n",
    "        \n",
    "    print(\"Processed\", len(reviews_single_page), \"reviews\")\n",
    "        \n",
    "def pagination(driver):\n",
    "    try:\n",
    "        next_page = driver.find_element_by_xpath('.//button[contains(@class,\"bv-content-btn-pages-load-more\")]') \n",
    "    except NoSuchElementException: \n",
    "        more = False\n",
    "    else:\n",
    "        more = True\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView()\", next_page)\n",
    "        next_page.click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    return more # True means there is another page to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Starting product: Chocolate Fudge Non-Dairy Bar\n",
      "Processed 22 reviews\n",
      "15\n",
      "Starting product: Chocolate Peanut Butter Ice Cream\n",
      "Processed 173 reviews\n",
      "16\n",
      "Starting product: Chocolate Salted Fudge Truffle Non-Dairy\n",
      "Processed 97 reviews\n",
      "17\n",
      "Starting product: Chocolate Sea Salt Caramel HEAVEN Light Ice Cream\n",
      "Processed 13 reviews\n",
      "18\n",
      "Starting product: Coconut Caramel Non-Dairy\n",
      "Processed 11 reviews\n",
      "19\n",
      "Starting product: Coconut Caramel Chocolate TRIO CRISPY LAYERS\n",
      "Processed 26 reviews\n",
      "20\n",
      "Starting product: Coconut Caramel Dark Chocolate Non-Dairy Bar\n",
      "Processed 31 reviews\n",
      "21\n",
      "Starting product: Coffee Ice Cream\n",
      "Processed 173 reviews\n",
      "22\n",
      "Starting product: Coffee Almond Crunch Ice Cream Bar\n",
      "Processed 42 reviews\n",
      "23\n",
      "Starting product: Coffee Chip Ice Cream\n",
      "Processed 111 reviews\n",
      "24\n",
      "Starting product: Coffee Vanilla Chocolate TRIO CRISPY LAYERS\n",
      "Processed 48 reviews\n",
      "25\n",
      "Starting product: Cold Brew Espresso Chip HEAVEN Light Ice Cream\n",
      "Processed 18 reviews\n",
      "26\n",
      "Starting product: Cookies and Cream Ice Cream\n",
      "Processed 23 reviews\n",
      "27\n",
      "Starting product: Double Belgian Chocolate Chip Ice Cream\n",
      "Processed 158 reviews\n",
      "28\n",
      "Starting product: Dulce de Leche Cookie Squares\n",
      "Processed 35 reviews\n",
      "29\n",
      "Starting product: Dulce de Leche Ice Cream\n",
      "Processed 209 reviews\n",
      "30\n",
      "Starting product: Green Tea Ice Cream\n",
      "Processed 109 reviews\n",
      "31\n",
      "Starting product: Honey Salted Caramel Almond Ice Cream\n",
      "Processed 103 reviews\n",
      "32\n",
      "Starting product: Irish Cream Cookie Squares\n",
      "Processed 14 reviews\n",
      "33\n",
      "Starting product: Irish Cream Brownie Ice Cream\n",
      "Processed 85 reviews\n",
      "34\n",
      "Starting product: Lemon Sorbet\n",
      "Processed 17 reviews\n",
      "35\n",
      "Starting product: Lemon Raspberry White Chocolate TRIO CRISPY LAYERS\n",
      "Processed 51 reviews\n",
      "36\n",
      "Starting product: Mango Ice Cream\n",
      "Processed 44 reviews\n",
      "37\n",
      "Starting product: Mango Sorbet\n",
      "Processed 20 reviews\n",
      "38\n",
      "Starting product: Mint Chip Ice Cream\n",
      "Processed 35 reviews\n",
      "39\n",
      "Starting product: Peanut Butter Cookie Squares\n",
      "Processed 14 reviews\n",
      "40\n",
      "Starting product: Peanut Butter Chip HEAVEN Light Ice Cream\n",
      "Processed 25 reviews\n",
      "41\n",
      "Starting product: Peanut Butter Chocolate Fudge Non-Dairy\n",
      "Processed 24 reviews\n",
      "42\n",
      "Starting product: Peanut Butter Chocolate Fudge Non-Dairy Bar\n",
      "Processed 32 reviews\n",
      "43\n",
      "Starting product: Peppermint Bark Ice Cream\n",
      "Processed 31 reviews\n",
      "44\n",
      "Starting product: Peppermint Bark Ice Cream Bar\n",
      "Processed 8 reviews\n",
      "45\n",
      "Starting product: Pineapple Coconut Ice Cream\n",
      "Processed 105 reviews\n",
      "46\n",
      "Starting product: Pistachio Ice Cream\n",
      "Processed 64 reviews\n",
      "47\n",
      "Starting product: Raspberry Sorbet\n",
      "Processed 14 reviews\n",
      "48\n",
      "Starting product: Rocky Road Ice Cream\n",
      "Processed 29 reviews\n",
      "49\n",
      "Starting product: Rosé & Cream Ice Cream\n",
      "Processed 23 reviews\n",
      "50\n",
      "Starting product: Ruby Cacao Ice Cream Bar\n",
      "Processed 31 reviews\n",
      "51\n",
      "Starting product: Ruby Cacao Crackle Pistachio Sweet Cream TRIO CRISPY LAYERS\n",
      "Processed 46 reviews\n",
      "52\n",
      "Starting product: Rum Raisin Ice Cream\n",
      "Processed 129 reviews\n",
      "53\n",
      "Starting product: Rum Tres Leches Ice Cream\n",
      "Processed 97 reviews\n",
      "54\n",
      "Starting product: Salted Caramel Chocolate TRIO CRISPY LAYERS\n",
      "Processed 55 reviews\n",
      "55\n",
      "Starting product: Strawberry Ice Cream\n",
      "Processed 108 reviews\n",
      "56\n",
      "Starting product: Strawberry Waffle Cone HEAVEN Light Ice Cream\n",
      "Processed 18 reviews\n",
      "57\n",
      "Starting product: Triple Chocolate TRIO CRISPY LAYERS\n",
      "Processed 52 reviews\n",
      "58\n",
      "Starting product: Vanilla Cookie Squares\n",
      "Processed 32 reviews\n",
      "59\n",
      "Starting product: Vanilla Ice Cream\n",
      "Processed 228 reviews\n",
      "60\n",
      "Starting product: Vanilla Soft Dipped Ice Cream Bar\n",
      "Processed 13 reviews\n",
      "61\n",
      "Starting product: Vanilla Bean Ice Cream\n",
      "Processed 115 reviews\n",
      "62\n",
      "Starting product: Vanilla Blackberry Chocolate TRIO CRISPY LAYERS\n",
      "Processed 74 reviews\n",
      "63\n",
      "Starting product: Vanilla Caramel White Chocolate TRIO CRISPY LAYERS\n",
      "Processed 32 reviews\n",
      "64\n",
      "Starting product: Vanilla Chocolate Chip Ice Cream\n",
      "Processed 46 reviews\n",
      "65\n",
      "Starting product: Vanilla Milk Chocolate Ice Cream Bar\n",
      "Processed 76 reviews\n",
      "66\n",
      "Starting product: Vanilla Milk Chocolate Almond Ice Cream Bar\n",
      "Processed 224 reviews\n",
      "67\n",
      "Starting product: Vanilla Swiss Almond Ice Cream\n",
      "Processed 129 reviews\n",
      "68\n",
      "Starting product: Whiskey Hazelnut Latte Ice Cream\n",
      "Processed 11 reviews\n",
      "69\n",
      "Starting product: White Chocolate Raspberry Ice Cream Bar\n",
      "Processed 11 reviews\n",
      "70\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-191-3c0bd09b370a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misCompleted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mproduct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.//div[contains(@class,\"flavors\")]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# make directory for images and reviews\n",
    "if not os.path.isdir(\"images_hd\"):\n",
    "    os.mkdir(\"images_hd\")\n",
    "\n",
    "# load into view\n",
    "for prod in products:\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView()\", prod)\n",
    "    \n",
    "i = 0\n",
    "df1=pd.read_csv(\"products_hd.csv\")\n",
    "completed = df1[\"name\"].values.tolist()\n",
    "while i < len(products):\n",
    "    print(i)\n",
    "    isCompleted = go_to_product_page(product, driver, completed)\n",
    "    if isCompleted:\n",
    "        i += 1\n",
    "        product = driver.find_elements_by_xpath('.//div[contains(@class,\"flavors\")]')[i]\n",
    "        continue\n",
    "        \n",
    "    product_filename = get_product_page_content(driver)\n",
    "        \n",
    "    # get all reviews for product\n",
    "    nextPage = True\n",
    "    while nextPage == True:\n",
    "        nextPage = pagination(driver)\n",
    "    get_reviews_single_page(driver, product_filename)    \n",
    "    \n",
    "    # return to start\n",
    "    driver.get(url)\n",
    "    i += 1\n",
    "    product = driver.find_elements_by_xpath('.//div[contains(@class,\"flavors\")]')[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize driver\n",
    "driver = webdriver.Chrome('./chromedriver.exe')\n",
    "\n",
    "# --- get starting page with list of products ---\n",
    "# define starting page\n",
    "home = \"https://www.talentigelato.com/\"\n",
    "url = home + \"product-category/talenti-gelato-flavors\"\n",
    "\n",
    "# load the page\n",
    "driver.get(url)  \n",
    "time.sleep(3)\n",
    "\n",
    "# get the list of products\n",
    "products = driver.find_elements_by_xpath('//a[@data-product-id]')\n",
    "i = 0 # starting product\n",
    "product = products[i]\n",
    "\n",
    "# close popup\n",
    "close_popup = driver.find_element_by_xpath('.//button[@class=\"close\" and @aria-hidden=\"true\"]')\n",
    "close_popup.click()\n",
    "time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 different formats for product description. They are all found under `<div class=\"the_content\">`.\n",
    "\n",
    "1.\n",
    "```HTML\n",
    "    <div class=\"left*\"> </div>\n",
    "    <div class=\"right*\"> </div>\n",
    "    <div class=\"pdp-recipe\"> </div>\n",
    "    <div> </div> <!-- empty div as a separator -->\n",
    "    <div class=\"pdp-recipe\"> ... </div> <!-- text description -->\n",
    "...\n",
    "```\n",
    "\n",
    "2. \n",
    "```HTML\n",
    "    <div class=\"pdp-recipe\"> </div>\n",
    "    <div class=\"description\">\n",
    "        <p> ... </p> <!-- text description -->\n",
    "    </div>\n",
    "...\n",
    "```\n",
    "\n",
    "3. \n",
    "```HTML\n",
    "    <div class=\"left*\"> </div>\n",
    "    <div class=\"right*\"> </div>\n",
    "    <p> ... </p> <!-- text description -->\n",
    "...\n",
    "```\n",
    "\n",
    "4.\n",
    "```HTML\n",
    "    <div class=\"left*\"> </div>\n",
    "    <div class=\"right*\"> </div>\n",
    "    <div class=\"description\"> ... </div> <!-- text description -->\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_product_page(product, driver, completed):\n",
    "    product_name = product.get_attribute('data-ct-information').strip()\n",
    "    if product_name in completed:\n",
    "        return True\n",
    "    else:\n",
    "        completed.append(product_name)\n",
    "        product_page_url = product.get_attribute(\"href\")\n",
    "        driver.get(product_page_url)\n",
    "        time.sleep(4) # wait for ratings to load\n",
    "        return False\n",
    "\n",
    "def get_product_page_content(driver):\n",
    "    product_name = driver.find_element_by_xpath('.//div[@class=\"product-description\"]//h2').text.strip()\n",
    "    print(\"Starting product:\", product_name) \n",
    "    with open(\"last_started.txt\", \"w\") as f:\n",
    "        f.write(product_name)\n",
    "    # ---- PRODUCT DESCRIPTION: 4 different formats -----\n",
    "    pd_fmt1 = driver.find_elements_by_xpath('.//div[@class=\"the_content\"]//div[@class=\"pdp-recipe\"]')\n",
    "    if len(pd_fmt1) == 1:\n",
    "        try:\n",
    "            product_description = driver.find_element_by_xpath('.//div[@class=\"the_content\"]//div[@class=\"description\"]/p').text\n",
    "        except NoSuchElementException:\n",
    "            product_description = pd_fmt1[0].text\n",
    "    elif len(pd_fmt1) == 2:\n",
    "        product_description = pd_fmt1[-1].text\n",
    "    elif len(pd_fmt1) == 0:\n",
    "        try:\n",
    "            pd_fmt2 = driver.find_element_by_xpath('.//div[child::div[contains(@id,\"left\")] and child::div[contains(@id,\"right\")]]/p')\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                pd_fmt3 = driver.find_element_by_xpath('.//div[child::div[contains(@id,\"left\")] and child::div[contains(@id,\"right\")]]/div[@class=\"description\"]')\n",
    "            except NoSuchElementException:\n",
    "                product_description = \"NA\"\n",
    "            else:\n",
    "                product_description = pd_fmt3.text\n",
    "        else:\n",
    "            product_description = pd_fmt2.text\n",
    "\n",
    "    else:\n",
    "        product_description = \"NA\"\n",
    "    # ---------------------------------------------\n",
    "    # --- RATING AND RATING COUNT ---\n",
    "    # Some products are formatted differently and do not show rating value and rating count, however we can impute them\n",
    "    # from looking at the review data\n",
    "    try:\n",
    "        product_rating = driver.find_element_by_xpath('.//div[@itemprop=\"ratingValue\"]').text\n",
    "    except NoSuchElementException:\n",
    "        product_rating = \"NA\"\n",
    "    try:\n",
    "        product_rating_ct = driver.find_element_by_xpath('.//meta[@itemprop=\"reviewCount\"]').get_attribute(\"content\")\n",
    "    except NoSuchElementException:\n",
    "        product_rating_ct = \"NA\"\n",
    "    \n",
    "    # ------ INGREDIENTS ---------\n",
    "    ingred_info = driver.find_element_by_xpath('.//div[@class=\"product-ingredients\"]').text.lstrip(\"INGREDIENTS\").split(\"May Contain\")[0].strip().rstrip(\".\").upper()\n",
    "    \n",
    "    # filename for reviews data and image\n",
    "    product_filename = \"-\".join(product_name.encode(\"ascii\", \"ignore\").decode().strip().split())\n",
    "    \n",
    "    # product info\n",
    "    df = pd.DataFrame({\"key\": [product_filename], \"name\": [product_name],\n",
    "                       \"description\": [product_description],\n",
    "                      \"rating\": [product_rating], \"rating_count\": [product_rating_ct],\n",
    "                      \"ingredients\": [ingred_info]})\n",
    "    \n",
    "    if os.path.isfile(\"products_talenti.csv\"):\n",
    "        df.to_csv(\"products_talenti.csv\", mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(\"products_talenti.csv\", mode=\"w\", header=True, index=False)    \n",
    "    \n",
    "    # get product image\n",
    "    if not os.path.isfile(\"images_talenti/%s.png\" % product_filename):\n",
    "        product_img_url = driver.find_element_by_xpath('.//img[@itemprop=\"image\"]').get_attribute(\"src\")\n",
    "        opener = urllib.request.build_opener()\n",
    "        opener.addheaders = [('User-agent', 'Chrome/85.0.4183.121')]\n",
    "        urllib.request.install_opener(opener)\n",
    "        urllib.request.urlretrieve(product_img_url, \"images_talenti/%s.png\" % product_filename)      \n",
    "        time.sleep(4)\n",
    "    \n",
    "    return product_filename\n",
    "    \n",
    "def get_reviews_single_page(driver, product_filename):\n",
    "    reviews_single_page = driver.find_elements_by_xpath('.//li[contains(@class,\"bv-content-review\")]')\n",
    "    \n",
    "    review_author, review_date, review_stars, review_title, review_yes, review_no, review_text = [], [], [], [], [], [], []\n",
    "    for review in reviews_single_page:\n",
    "        try:\n",
    "            review_author.append(review.find_element_by_xpath('.//button[@itemprop=\"author\"]/span').text)\n",
    "        except NoSuchElementException: \n",
    "            review_author.append(\"NA\") # anonymous\n",
    "        review_date.append(review.find_element_by_xpath('.//meta[@itemprop=\"datePublished\"]').get_attribute(\"content\"))\n",
    "        review_stars.append(review.find_element_by_xpath('.//meta[@itemprop=\"ratingValue\"]').get_attribute(\"content\"))\n",
    "        try:\n",
    "            review_title.append(review.find_element_by_xpath('.//h3[@itemprop=\"headline\"]').text)\n",
    "        except NoSuchElementException: \n",
    "            review_title.append(\"NA\")\n",
    "        try:\n",
    "            review_yes.append(review.find_element_by_xpath('.//button[contains(@class,\"feedback-yes\")]//span[@class=\"bv-content-btn-count\"]').text)\n",
    "            review_no.append(review.find_element_by_xpath('.//button[contains(@class,\"feedback-no\")]//span[@class=\"bv-content-btn-count\"]').text)\n",
    "        except NoSuchElementException:\n",
    "            review_yes.append(\"0\")\n",
    "            review_no.append(\"0\")\n",
    "        paragraphs = review.find_elements_by_xpath('.//div[@class=\"bv-content-summary-body-text\"]//p')\n",
    "        review_text.append(\"\\n\".join([p.text for p in paragraphs]))\n",
    "        \n",
    "    product_filename_column = [product_filename]*len(reviews_single_page) \n",
    "    df = pd.DataFrame({\"key\": product_filename_column, \"author\": review_author, \"date\": review_date, \n",
    "                       \"stars\": review_stars, \"title\": review_title, \"helpful_yes\": review_yes, \"helpful_no\": review_no, \n",
    "                       \"text\": review_text})\n",
    "\n",
    "    if os.path.isfile(\"reviews_talenti.csv\"):\n",
    "        df.to_csv(\"reviews_talenti.csv\", mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(\"reviews_talenti.csv\", mode=\"w\", header=True, index=False)\n",
    "        \n",
    "    print(\"Processed\", len(reviews_single_page), \"reviews\")\n",
    "        \n",
    "def pagination(driver):\n",
    "       \n",
    "    try:\n",
    "        next_page = driver.find_element_by_xpath('.//span[@class=\"bv-content-btn-pages-next\"]') \n",
    "    except NoSuchElementException: \n",
    "        more = False\n",
    "    else: \n",
    "        xofy = driver.find_elements_by_xpath('.//div[contains(@class,\"bv-content-pagination-pages-current\")]/span')[-1].text.strip()\n",
    "        xofy_text = xofy.split() # example: xofy_text = \"99–114 of 114 Reviews        &nbsp;\".split()\n",
    "        page_end = xofy_text[0].split(\"–\")[1] # xofy_text[0] = 99-114, xofy_text.split(\"-\")[1] = 114\n",
    "        total = xofy_text[2] # total = 114\n",
    "        if page_end == total:\n",
    "            more = False\n",
    "        else:\n",
    "            more = True\n",
    "            \n",
    "            driver.execute_script(\"arguments[0].scrollIntoView()\", next_page)\n",
    "            time.sleep(3)\n",
    "            next_page.click()\n",
    "            time.sleep(2)\n",
    "        \n",
    "    return more # True means there is another page to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "Starting product: VANILLA FUDGE COOKIE\n",
      "Processed 8 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 16 reviews\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-332a3cd17133>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mproduct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.//a[@data-product-id]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# make directory for images and reviews\n",
    "if not os.path.isdir(\"images_talenti\"):\n",
    "    os.mkdir(\"images_talenti\")\n",
    "\n",
    "# load into view\n",
    "for prod in products:\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView()\", prod)\n",
    "    \n",
    "# -- FIRST RUN --\n",
    "# completed = []\n",
    "# -- RESUMING --\n",
    "df1=pd.read_csv(\"products_talenti.csv\")\n",
    "completed = df1[\"name\"].values.tolist()\n",
    "\n",
    "while i < len(products):\n",
    "    print(i)\n",
    "    isCompleted = go_to_product_page(product, driver, completed)\n",
    "    if isCompleted:\n",
    "        i += 1\n",
    "        product = driver.find_elements_by_xpath('.//a[@data-product-id]')[i]\n",
    "        continue\n",
    "        \n",
    "    product_filename = get_product_page_content(driver)\n",
    "        \n",
    "    # --- REVIEWS ---\n",
    "    # close popup\n",
    "    try:\n",
    "        close_popup = driver.find_element_by_xpath('.//span[@id=\"closedelivery\"]')\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    else:\n",
    "        close_popup.click()\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # format 1: clickable review tab\n",
    "    try:\n",
    "        open_reviews = driver.find_element_by_xpath('.//a[@data-ct-information=\"Reviews\"]')\n",
    "    \n",
    "    # format 2: no click needed\n",
    "    except NoSuchElementException:\n",
    "        review_sec = driver.find_element_by_xpath('.//div[@class=\"heading_h4\"]/span[contains(text(),\"Reviews\")]')\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView()\", review_sec)\n",
    "    \n",
    "    # format 1 \n",
    "    else:\n",
    "        # scroll to reviews tab\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView()\", open_reviews)\n",
    "        time.sleep(4 + random.random()*2 )\n",
    "        try:\n",
    "            # open the reviews tab\n",
    "            open_reviews.click()\n",
    "            time.sleep(14 + random.random()*2 ) # wait for reviews to load\n",
    "        except: # extra scrolling may be needed\n",
    "            pass\n",
    "            \n",
    "    # both formats\n",
    "    finally:\n",
    "        # get all reviews for product\n",
    "        nextPage = True\n",
    "        while nextPage == True:\n",
    "            get_reviews_single_page(driver, product_filename)  \n",
    "            nextPage = pagination(driver)\n",
    "            \n",
    "    \n",
    "    # return to start\n",
    "    driver.get(url)\n",
    "    i += 1\n",
    "    product = driver.find_elements_by_xpath('.//a[@data-product-id]')[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if failed search on product, call this function to remove data before resuming\n",
    "def remove_data_pname(product_name):\n",
    "    key = \"-\".join(product_name.encode(\"ascii\", \"ignore\").decode().strip().split())\n",
    "    \n",
    "    df = pd.read_csv(\"products_talenti.csv\")\n",
    "    df[df[\"key\"] != key].to_csv(\"products_talenti.csv\", index=False)\n",
    "    \n",
    "    df = pd.read_csv(\"reviews_talenti.csv\")\n",
    "    df[df[\"key\"] != key].to_csv(\"reviews_talenti.csv\", index=False)\n",
    "    \n",
    "def clean_up():\n",
    "    with open(\"last_started.txt\", \"r\") as f:\n",
    "        product_name = f.read()\n",
    "        remove_data_pname(product_name)\n",
    "\n",
    "remove_data_pname(\"VANILLA FUDGE COOKIE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALPHONSO-MANGO-SORBETTO</td>\n",
       "      <td>ALPHONSO MANGO SORBETTO</td>\n",
       "      <td>Our simple and delicious Alphonso Mango Sorbet...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>139.0</td>\n",
       "      <td>MANGOS, WATER, SUGAR, DEXTROSE, LEMON JUICE, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BANANA-CARAMEL-CRUNCH</td>\n",
       "      <td>BANANA CARAMEL CRUNCH</td>\n",
       "      <td>This flavor was inspired by a classic southern...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MILK, BANANAS, SUGAR†, WHEAT FLOUR, CREAM, NON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BELGIAN-CHOCOLATE-GELATO</td>\n",
       "      <td>BELGIAN CHOCOLATE GELATO</td>\n",
       "      <td>Our Belgian Chocolate gelato is made with melt...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>MILK, SUGAR, CREAM, EGG AND EGG YOLK, DEXTROSE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLACK-RASPBERRY-CHOCOLATE-CHIP-GELATO</td>\n",
       "      <td>BLACK RASPBERRY CHOCOLATE CHIP GELATO</td>\n",
       "      <td>Tart and sweet, our Black Raspberry Chocolate ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>MILK, SUGAR, CREAM, BLACK RASPBERRIES, DEXTROS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLACK-RASPBERRY-VANILLA-PARFAIT</td>\n",
       "      <td>BLACK RASPBERRY VANILLA PARFAIT</td>\n",
       "      <td>This Layer was inspired by one of our favorite...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MILK, SUGAR, CREAM, BLACK RASPBERRY PUREE, ROL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     key  \\\n",
       "0                ALPHONSO-MANGO-SORBETTO   \n",
       "1                  BANANA-CARAMEL-CRUNCH   \n",
       "2               BELGIAN-CHOCOLATE-GELATO   \n",
       "3  BLACK-RASPBERRY-CHOCOLATE-CHIP-GELATO   \n",
       "4        BLACK-RASPBERRY-VANILLA-PARFAIT   \n",
       "\n",
       "                                    name  \\\n",
       "0                ALPHONSO MANGO SORBETTO   \n",
       "1                  BANANA CARAMEL CRUNCH   \n",
       "2               BELGIAN CHOCOLATE GELATO   \n",
       "3  BLACK RASPBERRY CHOCOLATE CHIP GELATO   \n",
       "4        BLACK RASPBERRY VANILLA PARFAIT   \n",
       "\n",
       "                                         description  rating  rating_count  \\\n",
       "0  Our simple and delicious Alphonso Mango Sorbet...     4.7         139.0   \n",
       "1  This flavor was inspired by a classic southern...     4.2          25.0   \n",
       "2  Our Belgian Chocolate gelato is made with melt...     4.8          27.0   \n",
       "3  Tart and sweet, our Black Raspberry Chocolate ...     4.0         105.0   \n",
       "4  This Layer was inspired by one of our favorite...     4.5          65.0   \n",
       "\n",
       "                                         ingredients  \n",
       "0  MANGOS, WATER, SUGAR, DEXTROSE, LEMON JUICE, C...  \n",
       "1  MILK, BANANAS, SUGAR†, WHEAT FLOUR, CREAM, NON...  \n",
       "2  MILK, SUGAR, CREAM, EGG AND EGG YOLK, DEXTROSE...  \n",
       "3  MILK, SUGAR, CREAM, BLACK RASPBERRIES, DEXTROS...  \n",
       "4  MILK, SUGAR, CREAM, BLACK RASPBERRY PUREE, ROL...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 6) (4074, 8)\n",
      "0 5\n",
      "key             0\n",
      "name            0\n",
      "description     4\n",
      "rating          4\n",
      "rating_count    4\n",
      "ingredients     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>COFFEE-COOKIE-CRUMBLE</td>\n",
       "      <td>COFFEE COOKIE CRUMBLE</td>\n",
       "      <td>Inspired by an affogato, Coffee Cookie Crumble...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>26</td>\n",
       "      <td>MILK, SUGAR†, CREAM, CHOCOLATE, EGG YOLKS, WAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LEMON-BERRY-PIE</td>\n",
       "      <td>LEMON BERRY PIE</td>\n",
       "      <td>Inspired by a classic summer dessert, this Lay...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>31</td>\n",
       "      <td>MILK, SUGAR†, CREAM, LEMON JUICE, WHEAT FLOUR,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MINT-FUDGE-COOKIE</td>\n",
       "      <td>MINT FUDGE COOKIE</td>\n",
       "      <td>In this Layer, our Mediterranean Mint Gelato i...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>52</td>\n",
       "      <td>MILK, SUGAR, CREAM, COCONUT OIL, WHEAT FLOUR, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>STRAWBERRY-HIBISCUS-SORBETTO</td>\n",
       "      <td>STRAWBERRY HIBISCUS SORBETTO</td>\n",
       "      <td>Sweet strawberries and real hibiscus flowers a...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>14</td>\n",
       "      <td>WATER, STRAWBERRIES, SUGAR, DEXTROSE, CORN SYR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key                          name  \\\n",
       "14         COFFEE-COOKIE-CRUMBLE         COFFEE COOKIE CRUMBLE   \n",
       "22               LEMON-BERRY-PIE               LEMON BERRY PIE   \n",
       "25             MINT-FUDGE-COOKIE             MINT FUDGE COOKIE   \n",
       "41  STRAWBERRY-HIBISCUS-SORBETTO  STRAWBERRY HIBISCUS SORBETTO   \n",
       "\n",
       "                                          description  rating  rating_count  \\\n",
       "14  Inspired by an affogato, Coffee Cookie Crumble...     4.4            26   \n",
       "22  Inspired by a classic summer dessert, this Lay...     4.2            31   \n",
       "25  In this Layer, our Mediterranean Mint Gelato i...     4.7            52   \n",
       "41  Sweet strawberries and real hibiscus flowers a...     4.4            14   \n",
       "\n",
       "                                          ingredients  \n",
       "14  MILK, SUGAR†, CREAM, CHOCOLATE, EGG YOLKS, WAT...  \n",
       "22  MILK, SUGAR†, CREAM, LEMON JUICE, WHEAT FLOUR,...  \n",
       "25  MILK, SUGAR, CREAM, COCONUT OIL, WHEAT FLOUR, ...  \n",
       "41  WATER, STRAWBERRIES, SUGAR, DEXTROSE, CORN SYR...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prod = pd.read_csv(\"products_talenti.csv\")\n",
    "rev = pd.read_csv(\"reviews_talenti.csv\")\n",
    "\n",
    "print(prod.shape, rev.shape)\n",
    "\n",
    "# remove duplicates\n",
    "print(prod.duplicated().sum(), rev.duplicated().sum())\n",
    "prod = prod[~prod.duplicated()]\n",
    "rev = rev[~rev.duplicated()] \n",
    "\n",
    "# impute missing rating & rating count by referring to reviews\n",
    "print(prod.isna().sum()) \n",
    "na_locs = prod[[\"rating\",\"rating_count\"]].isna().any(axis=1)\n",
    "prod_na = prod[na_locs]\n",
    "rev_gp = rev[[\"key\",\"stars\"]].groupby(\"key\")\n",
    "m = rev_gp.mean()\n",
    "c = rev_gp.count() \n",
    "for key in prod_na[\"key\"].values:\n",
    "    prod.loc[prod[\"key\"]==key, \"rating\"] = np.round(m.loc[m.index==key, \"stars\"].values, 1)\n",
    "    prod.loc[prod[\"key\"]==key, \"rating_count\"] = c.loc[c.index==key, \"stars\"].values\n",
    "prod[\"rating_count\"] = prod[\"rating_count\"].astype('int32')\n",
    "    \n",
    "display(prod[na_locs].head())\n",
    "\n",
    "prod.to_csv(\"products_talenti.csv\", index=False)\n",
    "rev.to_csv(\"reviews_talenti.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4069, 8), (5, 8))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev[~rev.duplicated()].shape, rev[rev.duplicated()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breyer's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize driver\n",
    "driver = webdriver.Chrome('./chromedriver.exe')\n",
    "\n",
    "# initialize headers for urllib.request\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Chrome/85.0.4183.121')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# --- get starting page with list of products ---\n",
    "# define starting page\n",
    "home = \"https://www.breyers.com\"\n",
    "url = home + \"/us/en/products.html\"\n",
    "\n",
    "# load the page\n",
    "driver.get(url)  \n",
    "time.sleep(3)\n",
    "\n",
    "# close popup\n",
    "close_popup = driver.find_element_by_xpath('.//a[@class=\"button-close\"]')\n",
    "close_popup.click()\n",
    "time.sleep(1.5)\n",
    "\n",
    "# -------- get the list of products ----------\n",
    "def show_more(driver):\n",
    "    more_products = True\n",
    "    while more_products:\n",
    "        btn = driver.find_element_by_xpath('.//button[@data-limit]')\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView()\", btn)\n",
    "        time.sleep(1.5)\n",
    "        driver.execute_script(\"window.scrollBy(0,-200);\") # navbar offset\n",
    "        time.sleep(1.5)\n",
    "        try:\n",
    "            btn.click()\n",
    "        except: # button no longer clickable ==> no more products\n",
    "            more_products = False\n",
    "        else:\n",
    "            time.sleep(3)\n",
    "show_more(driver)\n",
    "\n",
    "products = driver.find_elements_by_xpath('//div[contains(@class,\"box listing-item\")]')\n",
    "i = 0\n",
    "product = products[i]\n",
    "# --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize driver\n",
    "# driver = webdriver.Chrome('./chromedriver.exe')\n",
    "# url = \"https://www.breyers.com/us/en/products/classics/natural-vanilla.html\"\n",
    "\n",
    "# # load the page\n",
    "# driver.get(url)  \n",
    "# time.sleep(3)\n",
    "\n",
    "# # close popup\n",
    "# close_popup = driver.find_element_by_xpath('.//a[@class=\"button-close\"]')\n",
    "# close_popup.click()\n",
    "# time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_product_page(product, driver, completed):\n",
    "    product_name = product.find_element_by_xpath('.//div[@class=\"richText-content\"]/h3/a').text.rstrip(\"&nbsp;\").strip()\n",
    "    if product_name in completed:\n",
    "        return True\n",
    "    else:\n",
    "        completed.append(product_name)\n",
    "        product_page_url = product.find_element_by_xpath('.//div[@class=\"richText-content\"]/h3/a').get_attribute(\"href\")\n",
    "        driver.get(product_page_url)\n",
    "        time.sleep(2.5) # wait for ratings to load\n",
    "        return False\n",
    "\n",
    "def get_product_page_content(driver):\n",
    "    product_name = driver.find_elements_by_xpath('.//div[@class=\"richText-content\"]/h1')[0].text.split(\"\\n\")[0]\n",
    "    print(\"Starting product:\", product_name)\n",
    "    with open(\"last_started.txt\", \"w\") as f:\n",
    "        f.write(product_name)\n",
    "    product_description = driver.find_elements_by_xpath('.//div[@class=\"richText-content\"]/p/span')[0].text.strip()\n",
    "    product_rating = driver.find_element_by_xpath('.//div[@itemprop=\"ratingValue\"]').text\n",
    "    product_rating_ct = driver.find_element_by_xpath('.//meta[@itemprop=\"reviewCount\"]').get_attribute(\"content\")\n",
    "    \n",
    "    # filename for reviews data and image\n",
    "    product_filename = \"-\".join(product_name.encode(\"ascii\", \"ignore\").decode().strip().split())  \n",
    "\n",
    "    # get product image\n",
    "    if not os.path.isfile(\"images_breyers/%s.png\" % product_filename):\n",
    "        product_img = driver.find_elements_by_xpath('.//div[@class=\"imageGallery-view\"]//img')[0]\n",
    "        product_img_url = product_img.get_attribute(\"src\")\n",
    "        if not product_img_url:\n",
    "            product_img_url = product_img.get_attribute(\"data-src\")\n",
    "        if not product_img_url.startswith(\"https://www.breyers.com\"):\n",
    "            product_img_url = \"https://www.breyers.com\" + product_img_url\n",
    "        urllib.request.urlretrieve(product_img_url, \"images_breyers/%s.png\" % product_filename)     \n",
    "        time.sleep(4.5)\n",
    "    \n",
    "    # ------ INGREDIENTS ---------\n",
    "    # smart-label\n",
    "    try:\n",
    "        sl = driver.find_element_by_xpath('.//div[@class=\"smartlabel-button\"]//a')\n",
    "    except NoSuchElementException: \n",
    "        ingred_info = \"NA\"\n",
    "    else:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView()\", sl)\n",
    "        time.sleep(0.5)\n",
    "        driver.get(sl.get_attribute(\"href\"))\n",
    "        time.sleep(2.5)\n",
    "\n",
    "\n",
    "        ingred_nav = driver.find_element_by_xpath('.//div[contains(@class,\"TabNavigation\")]//span[contains(text(),\"Ingredients\")]')\n",
    "        ingred_nav.click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        ingred_list = driver.find_elements_by_xpath('.//div[contains(@class,\"IngredientList\")]//a')\n",
    "        ingred_info = \", \".join([ingred.text.upper() for ingred in ingred_list])\n",
    "        \n",
    "        # back to product page\n",
    "        driver.back()\n",
    "        time.sleep(1)\n",
    "        driver.back()\n",
    "        time.sleep(1)\n",
    "    # -----------------------------\n",
    "            \n",
    "    # product info\n",
    "    df = pd.DataFrame({\"key\": [product_filename], \"name\": [product_name],\n",
    "                       \"description\": [product_description],\n",
    "                      \"rating\": [product_rating], \"rating_count\": [product_rating_ct],\n",
    "                      \"ingredients\": [ingred_info]})\n",
    "    \n",
    "    if os.path.isfile(\"products_breyers.csv\"):\n",
    "        df.to_csv(\"products_breyers.csv\", mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(\"products_breyers.csv\", mode=\"w\", header=True, index=False)  \n",
    "    \n",
    "    return product_filename\n",
    "    \n",
    "\n",
    "def get_reviews_single_page(driver, product_filename):\n",
    "    time.sleep(3) # wait for reviews to load\n",
    "    \n",
    "    reviews_single_page = driver.find_elements_by_xpath('.//li[contains(@class,\"bv-content-review\")]')\n",
    "    \n",
    "    review_author, review_date, review_stars, review_title, review_yes, review_no, review_text = [], [], [], [], [], [], []\n",
    "    for review in reviews_single_page:\n",
    "        try:\n",
    "            review_author.append(review.find_element_by_xpath('.//span[@class=\"bv-author\"]').text)\n",
    "        except NoSuchElementException: \n",
    "            review_author.append(\"NA\") # anonymous\n",
    "        review_date.append(review.find_element_by_xpath('.//meta[@itemprop=\"datePublished\"]').get_attribute(\"content\"))\n",
    "        review_stars.append(review.find_element_by_xpath('.//meta[@itemprop=\"ratingValue\"]').get_attribute(\"content\"))\n",
    "        try:\n",
    "            review_title.append(review.find_element_by_xpath('.//h3[@itemprop=\"headline\"]').text.strip())\n",
    "        except NoSuchElementException: \n",
    "            review_title.append(\"NA\")\n",
    "        try:\n",
    "            review_yes.append(review.find_element_by_xpath('.//button[contains(@class,\"feedback-yes\")]//span[@class=\"bv-content-btn-count\"]').text)\n",
    "            review_no.append(review.find_element_by_xpath('.//button[contains(@class,\"feedback-no\")]//span[@class=\"bv-content-btn-count\"]').text)\n",
    "        except NoSuchElementException:\n",
    "            review_yes.append(\"0\")\n",
    "            review_no.append(\"0\")\n",
    "        review_paragraphs = review.find_elements_by_xpath('.//div[@class=\"bv-content-summary-body-text\"]')[0]\n",
    "        review_text.append( \"\\n\".join([p.text for p in review_paragraphs.find_elements_by_xpath('./p')]) )\n",
    "            \n",
    "    product_filename_column = [product_filename]*len(reviews_single_page) \n",
    "    df = pd.DataFrame({\"key\": product_filename_column, \"author\": review_author, \"date\": review_date, \n",
    "                       \"stars\": review_stars, \"title\": review_title, \"helpful_yes\": review_yes, \"helpful_no\": review_no, \n",
    "                       \"text\": review_text})\n",
    "\n",
    "    if os.path.isfile(\"reviews_breyers.csv\"):\n",
    "        df.to_csv(\"reviews_breyers.csv\", mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(\"reviews_breyers.csv\", mode=\"w\", header=True, index=False)\n",
    "        \n",
    "    print(\"Processed\", len(reviews_single_page), \"reviews\")\n",
    "        \n",
    "def pagination(driver):\n",
    "       \n",
    "    try:\n",
    "        next_page = driver.find_element_by_xpath('.//span[@class=\"bv-content-btn-pages-next\"]') \n",
    "    except NoSuchElementException: \n",
    "        more = False\n",
    "        print(\"Next page not found\")\n",
    "    else: \n",
    "        xofy = driver.find_elements_by_xpath('.//div[contains(@class,\"bv-content-pagination-pages-current\")]/span')[-1].text.strip()\n",
    "        xofy_text = xofy.split() # example: xofy_text = \"99–114 of 114 Reviews        &nbsp;\".split()\n",
    "        total = xofy_text[2] # total = 114\n",
    "        try: # format 1: last page reads \"99-114 of 114 Reviews\"\n",
    "            page_end = xofy_text[0].split(\"–\")[1] # xofy_text[0] = 99-114, xofy_text.split(\"-\")[1] = 114\n",
    "        except: # format 2: last page reads \"114 of 114 Reviews\"\n",
    "            page_end = xofy_text[0]\n",
    "        if page_end == total:\n",
    "            more = False\n",
    "        else:\n",
    "            more = True\n",
    "            \n",
    "            driver.execute_script(\"arguments[0].scrollIntoView()\", next_page)\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(\"window.scrollBy(0,-200);\") # navbar offset\n",
    "            time.sleep(1.5)\n",
    "            next_page.click()\n",
    "#             time.sleep(2)\n",
    "        \n",
    "    return more # True means there is another page to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Starting product: OREO®\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 1 reviews\n",
      "16\n",
      "Starting product: OREO® & CHIPS AHOY!® 2in1\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 14 reviews\n",
      "17\n",
      "Starting product: Vanilla Caramel\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 2 reviews\n",
      "18\n",
      "Starting product: Vanilla Caramel Gelato Indulgences\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 20 reviews\n",
      "19\n",
      "Starting product: Chocolate Mint\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 3 reviews\n",
      "20\n",
      "Starting product: Peach\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 14 reviews\n",
      "21\n",
      "Starting product: Vanilla Fudge Twirl\n",
      "Processed 5 reviews\n",
      "Processed 17 reviews\n",
      "22\n",
      "Starting product: CarbSmart™ Chocolate\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 14 reviews\n",
      "23\n",
      "Starting product: CarbSmart™ Peanut Butter\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 23 reviews\n",
      "24\n",
      "Starting product: Lactose Free Chocolate\n",
      "Processed 5 reviews\n",
      "Processed 19 reviews\n",
      "25\n",
      "Starting product: No Sugar Added Vanilla Chocolate Strawberry\n",
      "Processed 5 reviews\n",
      "Processed 29 reviews\n",
      "26\n",
      "Starting product: Non-Dairy Vanilla Peanut Butter\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 21 reviews\n",
      "27\n",
      "Starting product: Raspberry Cheesecake Gelato Indulgences\n",
      "Processed 5 reviews\n",
      "Processed 23 reviews\n",
      "28\n",
      "Starting product: REESE'S\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 1 reviews\n",
      "29\n",
      "Starting product: REESE'S & REESE'S PIECES 2in1\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 23 reviews\n",
      "30\n",
      "Starting product: No Sugar Added Caramel Swirl\n",
      "Processed 5 reviews\n",
      "Processed 14 reviews\n",
      "31\n",
      "Starting product: SNICKERS®\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 14 reviews\n",
      "32\n",
      "Starting product: SNICKERS® & M&M'S® 2in1\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 17 reviews\n",
      "33\n",
      "Starting product: CarbSmart™ Almond Bar\n",
      "Processed 5 reviews\n",
      "Processed 27 reviews\n",
      "34\n",
      "Starting product: HEATH & Waffle Cone 2in1\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 19 reviews\n",
      "35\n",
      "Starting product: No Sugar Added Butter Pecan\n",
      "Processed 5 reviews\n",
      "Processed 10 reviews\n",
      "36\n",
      "Starting product: CarbSmart™ Vanilla Bar\n",
      "Processed 5 reviews\n",
      "Processed 19 reviews\n",
      "37\n",
      "Starting product: HEATH\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 1 reviews\n",
      "38\n",
      "Starting product: Butter Pecan\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 9 reviews\n",
      "39\n",
      "Starting product: CarbSmart™ Fudge Bar\n",
      "Processed 5 reviews\n",
      "Processed 29 reviews\n",
      "40\n",
      "Starting product: CarbSmart™ Mint Fudge Bar\n",
      "Processed 5 reviews\n",
      "Processed 15 reviews\n",
      "41\n",
      "Starting product: OREO® Snack Cups 10ct\n",
      "Processed 2 reviews\n",
      "Next page not found\n",
      "42\n",
      "Starting product: REESE'S Chocolate\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 17 reviews\n",
      "43\n",
      "Starting product: Waffle Cone\n",
      "Processed 5 reviews\n",
      "Processed 15 reviews\n",
      "44\n",
      "Starting product: Creamsicle\n",
      "Processed 5 reviews\n",
      "Processed 21 reviews\n",
      "45\n",
      "Starting product: New York Style Cheesecake\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 1 reviews\n",
      "46\n",
      "Starting product: Rocky Road\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 7 reviews\n",
      "47\n",
      "Starting product: Cherry Vanilla\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 5 reviews\n",
      "48\n",
      "Starting product: Cookies & Cream\n",
      "Processed 5 reviews\n",
      "Processed 17 reviews\n",
      "49\n",
      "Starting product: Chocolate Chip Cookie Dough\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 24 reviews\n",
      "50\n",
      "Starting product: Non-Dairy OREO® Cookies & Cream\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 2 reviews\n",
      "51\n",
      "Starting product: Coffee\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 17 reviews\n",
      "52\n",
      "Starting product: Vanilla Chocolate\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "53\n",
      "Starting product: Chocolate Chip\n",
      "Processed 5 reviews\n",
      "Processed 25 reviews\n",
      "54\n",
      "Starting product: Extra Creamy Chocolate\n",
      "Processed 5 reviews\n",
      "Processed 8 reviews\n",
      "55\n",
      "Starting product: Black Raspberry Chocolate\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 3 reviews\n",
      "56\n",
      "Starting product: Chocolate Truffle\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 10 reviews\n",
      "57\n",
      "Starting product: Salted Caramel\n",
      "Processed 5 reviews\n",
      "Processed 15 reviews\n",
      "58\n",
      "Starting product: Ice Cream Cake\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 4 reviews\n",
      "59\n",
      "Starting product: Coconut Fudge\n",
      "Processed 5 reviews\n",
      "Processed 14 reviews\n",
      "60\n",
      "Starting product: Chocolate Peanut Butter\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 30 reviews\n",
      "Processed 18 reviews\n",
      "61\n",
      "Starting product: Natural Vanilla Snack Cups 10ct\n",
      "Processed 5 reviews\n",
      "Processed 23 reviews\n",
      "62\n",
      "Starting product: Butterscotch Blondie\n",
      "Processed 5 reviews\n",
      "Processed 15 reviews\n",
      "63\n",
      "Starting product: Chocolate Snack Cups 10ct\n",
      "Processed 5 reviews\n",
      "Processed 21 reviews\n",
      "64\n",
      "Starting product: CINNABON®\n",
      "Processed 5 reviews\n",
      "Processed 23 reviews\n",
      "65\n",
      "Starting product: CarbSmart™ Caramel Swirl Bar\n",
      "Processed 5 reviews\n",
      "Processed 13 reviews\n",
      "66\n",
      "Starting product: Layered Dessert S'mores\n",
      "Processed 5 reviews\n",
      "Processed 26 reviews\n",
      "67\n",
      "Starting product: Layered Dessert Peach Cobbler\n",
      "Processed 5 reviews\n",
      "Processed 30 reviews\n",
      "Processed 3 reviews\n",
      "68\n",
      "Starting product: Layered Dessert Brownie Cheesecake\n",
      "Processed 5 reviews\n",
      "Processed 20 reviews\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-45882a57d4aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mshow_more\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mproduct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.//div[contains(@class,\"box listing-item\")]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# make directory for images and reviews\n",
    "if not os.path.isdir(\"images_breyers\"):\n",
    "    os.mkdir(\"images_breyers\")\n",
    "\n",
    "# ----- load into view -----\n",
    "for prod in products:\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView()\", prod)\n",
    "# -------------------------\n",
    "\n",
    "# -- FIRST RUN --\n",
    "# completed = []\n",
    "# -- RESUMING --\n",
    "df1=pd.read_csv(\"products_breyers.csv\")\n",
    "completed = df1[\"name\"].values.tolist()\n",
    "\n",
    "while i < len(products):\n",
    "    print(i)\n",
    "    isCompleted = go_to_product_page(product, driver, completed)\n",
    "    if isCompleted:\n",
    "        i += 1\n",
    "        product = driver.find_elements_by_xpath('.//div[contains(@class,\"box listing-item\")]')[i]\n",
    "        continue\n",
    "        \n",
    "    product_filename = get_product_page_content(driver)\n",
    "    \n",
    "    # get all reviews for product\n",
    "    nextPage = True\n",
    "    while nextPage == True:\n",
    "        get_reviews_single_page(driver, product_filename)  \n",
    "        nextPage = pagination(driver)\n",
    "            \n",
    "    # return to start\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    show_more(driver)\n",
    "    i += 1\n",
    "    product = driver.find_elements_by_xpath('.//div[contains(@class,\"box listing-item\")]')[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if failed search on product, call this function to remove data before resuming\n",
    "# def remove_data_pname(product_name):\n",
    "#     key = \"-\".join(product_name.encode(\"ascii\", \"ignore\").decode().strip().split())\n",
    "    \n",
    "#     df = pd.read_csv(\"products_breyers.csv\")\n",
    "#     df[df[\"key\"] != key].to_csv(\"products_breyers.csv\", index=False)\n",
    "    \n",
    "#     df = pd.read_csv(\"reviews_breyers.csv\")\n",
    "#     df[df[\"key\"] != key].to_csv(\"reviews_breyers.csv\", index=False)\n",
    "    \n",
    "# def clean_up():\n",
    "#     with open(\"last_started.txt\", \"r\") as f:\n",
    "#         product_name = f.read()\n",
    "#         remove_data_pname(product_name)\n",
    "\n",
    "# # print(pd.read_csv(\"products_breyers.csv\").tail(1)[\"name\"].values)\n",
    "# remove_data_pname(\"OREO®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WATER, SUGAR, CORN SYRUP, CHOCOLATE, COCONUT OIL, POWDERED SUGAR, SUGAR, CORN STARCH, COCOA BUTTER, SUNFLOWER OIL, COCOA PROCESSED WITH ALKALI, COCOA, SOYBEAN OIL, SOY LECITHIN, PECTIN, VANILLA EXTRACT, SALT, SUNFLOWER LECITHIN\n"
     ]
    }
   ],
   "source": [
    "# initialize driver\n",
    "driver = webdriver.Chrome('./chromedriver.exe')\n",
    "\n",
    "# --- get starting page with list of products ---\n",
    "# define starting page\n",
    "url = \"https://www.haagendazs.us/products/non-dairy/chocolate-fudge-non-dairy-bar\"\n",
    "\n",
    "# load the page\n",
    "driver.get(url)  \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"products_hd.csv\")\n",
    "df2[\"ingredients\"] = df2[\"ingredients\"].apply(lambda x: x.upper().rstrip(\".\"))\n",
    "df2.to_csv(\"products_hd_fixed.csv\", index=False)\n",
    "\n",
    "df1 = pd.read_csv(\"reviews_hd.csv\")\n",
    "df1[~df1.duplicated()].to_csv(\"reviews_hd_fixed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates and make combined dataset\n",
    "- For each brand, remove duplicated records in each product and reviews file\n",
    "- Examine missing values\n",
    "- Note: Chocolate-Chip-Cookie-Dough is a key that appears twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_bj = pd.read_csv(\"kaggle/bj/products.csv\")\n",
    "p_hd = pd.read_csv(\"kaggle/hd/products.csv\")\n",
    "p_t = pd.read_csv(\"kaggle/talenti/products.csv\")\n",
    "p_br = pd.read_csv(\"kaggle/breyers/products.csv\")\n",
    "\n",
    "r_bj = pd.read_csv(\"kaggle/bj/reviews.csv\")\n",
    "r_hd = pd.read_csv(\"kaggle/hd/reviews.csv\")\n",
    "r_t = pd.read_csv(\"kaggle/talenti/reviews.csv\")\n",
    "r_br = pd.read_csv(\"kaggle/breyers/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "p_dfs = [p_bj, p_hd, p_t, p_br]\n",
    "r_dfs = [r_bj, r_hd, r_t, r_br]\n",
    "brands = [\"bj\",\"hd\",\"talenti\",\"breyers\"]\n",
    "for i,brand in enumerate(brands):\n",
    "    key_map = {key:str(str(j) + \"_\" + brand) for j,key in enumerate(p_dfs[i][\"key\"].values)}\n",
    "    p_dfs[i][\"key\"] = p_dfs[i].replace(key_map)\n",
    "    r_dfs[i][\"key\"] = r_dfs[i].replace(key_map)\n",
    "    \n",
    "    for img_name in next(os.walk(\"kaggle/\" + brand +\"/images\"))[2]:\n",
    "        key_name = img_name.split(\".png\")[0]\n",
    "        try:\n",
    "            new_key = key_map[key_name]\n",
    "        except:\n",
    "            print(key_name)\n",
    "        copyfile(\"kaggle/\" + brand + \"/images/\" + img_name, \"kaggle/\" + brand + \"/images/\" + new_key + \".png\")\n",
    "        os.remove(\"kaggle/\" + brand + \"/images/\" + img_name)\n",
    "    p_dfs[i].to_csv(\"kaggle/\" + brand + \"/products.csv\", index=False)\n",
    "    r_dfs[i].to_csv(\"kaggle/\" + brand + \"/reviews.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_talenti</td>\n",
       "      <td>ALPHONSO MANGO SORBETTO</td>\n",
       "      <td>Our simple and delicious Alphonso Mango Sorbet...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>139</td>\n",
       "      <td>MANGOS, WATER, SUGAR, DEXTROSE, LEMON JUICE, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_talenti</td>\n",
       "      <td>BANANA CARAMEL CRUNCH</td>\n",
       "      <td>This flavor was inspired by a classic southern...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>25</td>\n",
       "      <td>MILK, BANANAS, SUGAR†, WHEAT FLOUR, CREAM, NON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_talenti</td>\n",
       "      <td>BELGIAN CHOCOLATE GELATO</td>\n",
       "      <td>Our Belgian Chocolate gelato is made with melt...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>27</td>\n",
       "      <td>MILK, SUGAR, CREAM, EGG AND EGG YOLK, DEXTROSE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_talenti</td>\n",
       "      <td>BLACK RASPBERRY CHOCOLATE CHIP GELATO</td>\n",
       "      <td>Tart and sweet, our Black Raspberry Chocolate ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>105</td>\n",
       "      <td>MILK, SUGAR, CREAM, BLACK RASPBERRIES, DEXTROS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_talenti</td>\n",
       "      <td>BLACK RASPBERRY VANILLA PARFAIT</td>\n",
       "      <td>This Layer was inspired by one of our favorite...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>65</td>\n",
       "      <td>MILK, SUGAR, CREAM, BLACK RASPBERRY PUREE, ROL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key                                   name  \\\n",
       "0  0_talenti                ALPHONSO MANGO SORBETTO   \n",
       "1  1_talenti                  BANANA CARAMEL CRUNCH   \n",
       "2  2_talenti               BELGIAN CHOCOLATE GELATO   \n",
       "3  3_talenti  BLACK RASPBERRY CHOCOLATE CHIP GELATO   \n",
       "4  4_talenti        BLACK RASPBERRY VANILLA PARFAIT   \n",
       "\n",
       "                                         description  rating  rating_count  \\\n",
       "0  Our simple and delicious Alphonso Mango Sorbet...     4.7           139   \n",
       "1  This flavor was inspired by a classic southern...     4.2            25   \n",
       "2  Our Belgian Chocolate gelato is made with melt...     4.8            27   \n",
       "3  Tart and sweet, our Black Raspberry Chocolate ...     4.0           105   \n",
       "4  This Layer was inspired by one of our favorite...     4.5            65   \n",
       "\n",
       "                                         ingredients  \n",
       "0  MANGOS, WATER, SUGAR, DEXTROSE, LEMON JUICE, C...  \n",
       "1  MILK, BANANAS, SUGAR†, WHEAT FLOUR, CREAM, NON...  \n",
       "2  MILK, SUGAR, CREAM, EGG AND EGG YOLK, DEXTROSE...  \n",
       "3  MILK, SUGAR, CREAM, BLACK RASPBERRIES, DEXTROS...  \n",
       "4  MILK, SUGAR, CREAM, BLACK RASPBERRY PUREE, ROL...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dfs[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bj\n",
      "(57, 7) (7943, 8)\n",
      "(57, 7) (7943, 8)\n",
      "hd\n",
      "(70, 6) (4655, 12)\n",
      "(70, 6) (4655, 12)\n",
      "talenti\n",
      "(45, 6) (4069, 8)\n",
      "(45, 6) (4069, 8)\n",
      "breyers\n",
      "(69, 6) (5009, 8)\n",
      "(69, 6) (5007, 8)\n"
     ]
    }
   ],
   "source": [
    "p_dfs = [p_bj, p_hd, p_t, p_br]\n",
    "r_dfs = [r_bj, r_hd, r_t, r_br]\n",
    "brands = [\"bj\",\"hd\",\"talenti\",\"breyers\"]\n",
    "for i,brand in enumerate(brands):\n",
    "    print(brand)\n",
    "    print(p_dfs[i].shape, r_dfs[i].shape)\n",
    "    if \"Chocolate-Chip-Cookie-Dough\" in p_dfs[i][\"key\"].values:\n",
    "        p_dfs[i].loc[p_dfs[i][\"key\"]==\"Chocolate-Chip-Cookie-Dough\",\"key\"] = \"Chocolate-Chip-Cookie-Dough_\" + brand\n",
    "    if \"Chocolate-Chip-Cookie-Dough\" in r_dfs[i][\"key\"].values:\n",
    "        r_dfs[i].loc[r_dfs[i][\"key\"]==\"Chocolate-Chip-Cookie-Dough\",\"key\"] = \"Chocolate-Chip-Cookie-Dough_\" + brand\n",
    "\n",
    "    p_dfs[i] = p_dfs[i][~p_dfs[i].duplicated()]\n",
    "    r_dfs[i] = r_dfs[i][~r_dfs[i].duplicated()]\n",
    "    print(p_dfs[i].shape, r_dfs[i].shape)\n",
    "    \n",
    "    p_dfs[i].to_csv(\"products_\" + brand + \".csv\", index=False)\n",
    "    r_dfs[i].to_csv(\"reviews_\" + brand + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_bj = pd.read_csv(\"kaggle/bj/products.csv\")\n",
    "p_hd = pd.read_csv(\"kaggle/hd/products.csv\")\n",
    "p_t = pd.read_csv(\"kaggle/talenti/products.csv\")\n",
    "p_br = pd.read_csv(\"kaggle/breyers/products.csv\")\n",
    "\n",
    "r_bj = pd.read_csv(\"kaggle/bj/reviews.csv\")\n",
    "r_hd = pd.read_csv(\"kaggle/hd/reviews.csv\")\n",
    "r_t = pd.read_csv(\"kaggle/talenti/reviews.csv\")\n",
    "r_br = pd.read_csv(\"kaggle/breyers/reviews.csv\")\n",
    "\n",
    "p_dfs = [p_bj, p_hd, p_t, p_br]\n",
    "r_dfs = [r_bj, r_hd, r_t, r_br]\n",
    "brands = [\"bj\",\"hd\",\"talenti\",\"breyers\"]\n",
    "for i,brand in enumerate(brands):\n",
    "    brand_col = pd.DataFrame({\"brand\":[brand]*len(p_dfs[i])})\n",
    "    p_dfs[i] = pd.concat([brand_col,p_dfs[i]], axis=1)\n",
    "    brand_col2 = pd.DataFrame({\"brand\":[brand]*len(r_dfs[i])})\n",
    "    r_dfs[i] = pd.concat([brand_col2,r_dfs[i]], axis=1)\n",
    "    \n",
    "p_concat = pd.concat(p_dfs, axis=0, ignore_index=True)\n",
    "r_concat = pd.concat(r_dfs, axis=0, ignore_index=True)\n",
    "p_concat.to_csv(\"kaggle/combined/products.csv\", index=False)\n",
    "r_concat.to_csv(\"kaggle/combined/reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand           object\n",
       "key             object\n",
       "author          object\n",
       "date            object\n",
       "stars            int64\n",
       "title           object\n",
       "helpful_yes    float64\n",
       "helpful_no     float64\n",
       "text            object\n",
       "taste          float64\n",
       "ingredients    float64\n",
       "texture        float64\n",
       "likes           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_concat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
